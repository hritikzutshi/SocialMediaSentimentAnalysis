{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import warnings \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv')\n",
    "train1 = pd.read_csv('https://raw.githubusercontent.com/hritikzutshi/SocialMediaSentimentAnalysis/master/djangotest/proj/Corona_NLP_train.csv',encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original=train.copy()\n",
    "train1_original=train1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape\n",
    "train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/test.csv')\n",
    "test1 = pd.read_csv('https://raw.githubusercontent.com/hritikzutshi/SocialMediaSentimentAnalysis/master/djangotest/proj/Corona_NLP_test.csv',encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.drop('TweetAt', inplace=True, axis=1)\n",
    "train1.drop('ScreenName', inplace=True, axis=1)\n",
    "train1.drop('Location', inplace=True, axis=1)\n",
    "\n",
    "test1.drop('TweetAt', inplace=True, axis=1)\n",
    "test1.drop('ScreenName', inplace=True, axis=1)\n",
    "test1.drop('Location', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1['tweet'] = train1.OriginalTweet\n",
    "train1[\"tweet\"] = train1[\"tweet\"].astype(str)\n",
    "train1.drop('OriginalTweet', inplace=True, axis=1)\n",
    "\n",
    "\n",
    "test1['tweet'] = test1.OriginalTweet\n",
    "test1[\"tweet\"] = test1[\"tweet\"].astype(str)\n",
    "test1.drop('OriginalTweet', inplace=True, axis=1)\n",
    "\n",
    "\n",
    "def classes_def(x):\n",
    "    if x ==  \"Extremely Positive\":\n",
    "        return 1\n",
    "    elif x == \"Extremely Negative\":\n",
    "        return 0\n",
    "    elif x == \"Negative\":\n",
    "        return 0\n",
    "    elif x ==  \"Positive\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "\n",
    "train1['label']=train1['Sentiment'].apply(lambda x:classes_def(x))\n",
    "test1['label']=test1['Sentiment'].apply(lambda x:classes_def(x))\n",
    "\n",
    "train1.label.value_counts(normalize= True)\n",
    "\n",
    "train1.drop('Sentiment', inplace=True, axis=1)\n",
    "test1.drop('Sentiment', inplace=True, axis=1)\n",
    "\n",
    "train1 = train1.rename(columns={'UserName':'id'})\n",
    "test1 = test1.rename(columns={'UserName':'id'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=train1[['id','label','tweet']]\n",
    "test1=test1[['id','label','tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original=test.copy()\n",
    "test1_original=test1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we see that there are a total of 17197 tweets in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We combine Train and Test datasets for pre-processing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine = train.append(test,ignore_index=True,sort=True)\n",
    "# combine = combine.append(train1,ignore_index=True,sort=True)\n",
    "# combine = combine.append(test1,ignore_index=True,sort=True)\n",
    "\n",
    "combine = train.append(test,ignore_index=True,sort=True)\n",
    "combine.isnull().sum().sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is a user-defined function to remove unwanted text patterns from the tweets. It takes two arguments, one is the original string of text and the other is the pattern of text that we want to remove from the string. The function returns the same input string but without the given pattern. We will use this function to remove the pattern ‘@user’ from all the tweets in our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(text,pattern):    \n",
    "    # re.findall() finds the pattern i.e @user and puts it in a list for further task\n",
    "    r = re.findall(pattern,text)    \n",
    "    # re.sub() removes @user from the sentences in the dataset\n",
    "    for i in r:\n",
    "        text = re.sub(i,\"\",text)    \n",
    "    return text\n",
    "    \n",
    "def remove_urls(text):\n",
    "    url_remove = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_remove.sub(r'', text)\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine['tweet'] = np.vectorize(remove_pattern)(combine['tweet'], \"@[\\w]*\")\n",
    "\n",
    "combine['tweet']=combine['tweet'].apply(lambda x:remove_html(x))\n",
    "\n",
    "combine['tweet']=combine['tweet'].apply(lambda x:remove_urls(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punctuations, numbers and special characters do not help much. It is better to remove them from the text just as we removed the twitter handles. Here we will replace everything except characters and hashtags with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine['tweet'] = combine['tweet'].str.replace(\"[^a-zA-Z#]\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to be a little careful here in selecting the length of the words which we want to remove. So, I have decided to remove all the words having length 3 or less. For example, terms like “hmm”, “oh” are of very little use. It is better to get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine['tweet'] = combine['tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will tokenize all the cleaned tweets in our dataset. Tokens are individual terms or words, and tokenization is the process of splitting a string of text into tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweet = combine['tweet'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is a rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s” etc) from a word. For example, For example – “play”, “player”, “played”, “plays” and “playing” are the different variations of the word – “play”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [ps.stem(i) for i in x])\n",
    "\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let’s stitch these tokens back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokenized_tweet)):\n",
    "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "\n",
    "combine['tweet'] = tokenized_tweet\n",
    "combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Packages necessary for generating a WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud,ImageColorGenerator\n",
    "from PIL import Image\n",
    "import urllib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Store all the words from the dataset which are non-racist/sexist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_positive = ' '.join(text for text in combine['tweet'][combine['label']==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see most of the words are positive or neutral. With happy, smile, and love being the most frequent ones. Hence, most of the frequent words are compatible with the sentiment which is non racist/sexists tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the image with the dataset\n",
    "Mask = np.array(Image.open(requests.get('http://clipart-library.com/image_gallery2/Twitter-PNG-Image.png', stream=True).raw))\n",
    "\n",
    "# We use the ImageColorGenerator library from Wordcloud \n",
    "# Here we take the color of the image and impose it over our wordcloud\n",
    "image_colors = ImageColorGenerator(Mask)\n",
    "\n",
    "# Now we use the WordCloud function from the wordcloud library \n",
    "wc = WordCloud(background_color='black', height=1500, width=4000,mask=Mask).generate(all_words_positive)\n",
    "\n",
    "# Size of the image generated \n",
    "plt.figure(figsize=(10,20))\n",
    "\n",
    "# Here we recolor the words from the dataset to the image's color\n",
    "# recolor just recolors the default colors to the image's blue color\n",
    "# interpolation is used to smooth the image generated \n",
    "plt.imshow(wc.recolor(color_func=image_colors),interpolation=\"hamming\")\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store all the words from the dataset which are racist/sexist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_negative = ' '.join(text for text in combine['tweet'][combine['label']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can clearly see, most of the words have negative connotations. So, it seems we have a pretty good text data to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the image with the dataset\n",
    "Mask = np.array(Image.open(requests.get('http://clipart-library.com/image_gallery2/Twitter-PNG-Image.png', stream=True).raw))\n",
    "\n",
    "# We use the ImageColorGenerator library from Wordcloud \n",
    "# Here we take the color of the image and impose it over our wordcloud\n",
    "image_colors = ImageColorGenerator(Mask)\n",
    "\n",
    "# Now we use the WordCloud function from the wordcloud library \n",
    "wc = WordCloud(background_color='black', height=1500, width=4000,mask=Mask).generate(all_words_negative)\n",
    "\n",
    "# Size of the image generated \n",
    "plt.figure(figsize=(10,20))\n",
    "\n",
    "# Here we recolor the words from the dataset to the image's color\n",
    "# recolor just recolors the default colors to the image's blue color\n",
    "# interpolation is used to smooth the image generated \n",
    "plt.imshow(wc.recolor(color_func=image_colors),interpolation=\"gaussian\")\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract hashtags from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hashtags_Extract(x):\n",
    "    hashtags=[]\n",
    "    \n",
    "    # Loop over the words in the tweet\n",
    "    for i in x:\n",
    "        ht = re.findall(r'#(\\w+)',i)\n",
    "        hashtags.append(ht)\n",
    "    \n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A nested list of all the hashtags from the positive reviews from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_positive = Hashtags_Extract(combine['tweet'][combine['label']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we unnest the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_positive_unnest = sum(ht_positive,[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A nested list of all the hashtags from the negative reviews from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_negative = Hashtags_Extract(combine['tweet'][combine['label']==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we unnest the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_negative_unnest = sum(ht_negative,[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting the frequency of the words having Positive Sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_positive = nltk.FreqDist(ht_positive_unnest)\n",
    "\n",
    "word_freq_positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dataframe for the most frequently used words in hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = pd.DataFrame({'Hashtags':list(word_freq_positive.keys()),'Count':list(word_freq_positive.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the barplot for the 10 most frequent words used for hashtags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_plot = df_positive.nlargest(20,columns='Count') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df_positive_plot,y='Hashtags',x='Count')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting the frequency of the words having Negative Sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_negative = nltk.FreqDist(ht_negative_unnest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dataframe for the most frequently used words in hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative = pd.DataFrame({'Hashtags':list(word_freq_negative.keys()),'Count':list(word_freq_negative.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the barplot for the 10 most frequent words used for hashtags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_plot = df_negative.nlargest(20,columns='Count') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df_negative_plot,y='Hashtags',x='Count')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "#combine = clean_dataset(combine)\n",
    "np.nan_to_num(combine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using features from TF-IDF for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf=TfidfVectorizer(sublinear_tf=True, min_df=5,stop_words='english')\n",
    "\n",
    "tfidf_matrix=tfidf.fit_transform(combine['tweet'])\n",
    "\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.todense())\n",
    "\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_matrix[:31962]\n",
    "np.any(np.isnan(df_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf,x_valid_tfidf,y_train_tfidf,y_valid_tfidf = train_test_split(tfidf_matrix,train['label'],test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_Reg = LogisticRegression(solver = 'liblinear', random_state = 42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_Reg.fit(x_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tfidf = Log_Reg.predict(x_valid_tfidf)\n",
    "\n",
    "prediction_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the F1 score and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_tfidf=prediction_tfidf[:,1]>=0.3\n",
    "\n",
    "# # converting the results to integer type\n",
    "# prediction_int_tfidf=prediction_tfidf.astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating f1 score\n",
    "log_score = f1_score(y_valid_tfidf, prediction_tfidf)\n",
    "log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_accuracy = accuracy_score(y_valid_tfidf,prediction_tfidf)\n",
    "log_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TF-IDF Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tfidf=XGBClassifier(random_state=29,learning_rate=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tfidf.fit(x_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first part of the list is predicting probabilities for label:0 \n",
    "# and the second part of the list is predicting probabilities for label:1\n",
    "xgb_tfidf=model_tfidf.predict(x_valid_tfidf)\n",
    "\n",
    "xgb_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the F1 score and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if prediction is greater than or equal to 0.3 than 1 else 0\n",
    "# Where 0 is for positive sentiment tweets and 1 for negative sentiment tweets\n",
    "# xgb_tfidf=xgb_tfidf[:,1]>=0.3\n",
    "\n",
    "# # converting the results to integer type\n",
    "# xgb_int_tfidf=xgb_tfidf.astype(np.int)\n",
    "\n",
    "# calculating f1 score\n",
    "xbg_score=f1_score(y_valid_tfidf,xgb_tfidf)\n",
    "\n",
    "xbg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbg_accuracy = accuracy_score(y_valid_tfidf,xgb_tfidf)\n",
    "xbg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(x_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc.predict(x_valid_tfidf)\n",
    "\n",
    "rfc_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating F1 Score and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if prediction is greater than or equal to 0.3 than 1 else 0\n",
    "# Where 0 is for positive sentiment tweets and 1 for negative sentiment tweets\n",
    "# rfc_pred=rfc_pred[:,1]>=0.3\n",
    "\n",
    "# # converting the results to integer type\n",
    "# rfc_int_tfidf=rfc_pred.astype(np.int)\n",
    "\n",
    "# calculating f1 score\n",
    "rfc_score=f1_score(y_valid_tfidf,rfc_pred)\n",
    "rfc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_accuracy = accuracy_score(y_valid_tfidf, rfc_pred )\n",
    "rfc_accuracy"
   ]
  },
  {
   "source": [
    "# Multinomial Naive Bayes\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = nb.predict(x_valid_tfidf)\n",
    "nb_model"
   ]
  },
  {
   "source": [
    "### Calculating F1 Score and accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_model=nb_model[:,1]>=0.3\n",
    "\n",
    "# # converting the results to integer type\n",
    "# nb_model=nb_model.astype(np.int)\n",
    "\n",
    "# calculating f1 score\n",
    "naive_bays_score=f1_score(y_valid_tfidf,nb_model)\n",
    "\n",
    "naive_bays_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bays_accuracy = accuracy_score(y_valid_tfidf,nb_model)\n",
    "naive_bays_accuracy"
   ]
  },
  {
   "source": [
    "# Linear support vector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC()\n",
    "lsvc.fit(x_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsvc_new = CalibratedClassifierCV(lsvc,cv='prefit')\n",
    "# lscv_new = lsvc_new.fit(x_valid_tfidf,y_valid_tfidf) \n",
    "lsvc_model = lsvc.predict(x_valid_tfidf)\n",
    "lsvc_model"
   ]
  },
  {
   "source": [
    "### Calculating F1 Score and accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsvc_model=lsvc_model[:,1]>=0.3\n",
    "\n",
    "# # converting the results to integer type\n",
    "# lsvc_model=lsvc_model.astype(np.int)\n",
    "\n",
    "# calculating f1 score\n",
    "lsvc_score=f1_score(y_valid_tfidf,lsvc_model)\n",
    "\n",
    "lsvc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_accuracy = accuracy_score(y_valid_tfidf,lsvc_model)\n",
    "lsvc_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo=['LogisticRegression','XGBoost','RandomForest','NaiveBays','LinearSVC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [log_score,xbg_score,rfc_score,naive_bays_score,lsvc_score]\n",
    "\n",
    "compare=pd.DataFrame({'Model':Algo,'F1-Score':score},index=[i for i in range(1,6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "sns.pointplot(x='Model',y='F1-Score',data=compare)\n",
    "\n",
    "plt.title('Model Vs F1-Score')\n",
    "plt.xlabel('MODEL')\n",
    "plt.ylabel('F1-Score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [log_accuracy,xbg_accuracy,rfc_accuracy,naive_bays_accuracy,lsvc_accuracy]\n",
    "\n",
    "compare=pd.DataFrame({'Model':Algo,'Accuracy':accuracy},index=[i for i in range(1,6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "sns.pointplot(x='Model',y='Accuracy',data=compare)\n",
    "\n",
    "plt.title('Model Vs Accuracy')\n",
    "plt.xlabel('MODEL')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the best possible model to predict for the test data\n",
    "\n",
    "#### From the above comaprison graph we can see that Logistic Regression trained using TF-IDF features gives us the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = tfidf_matrix[31962:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = Log_Reg.predict_proba(test_tfidf)\n",
    "\n",
    "test_pred_int = test_pred[:,1] >= 0.3\n",
    "\n",
    "test_pred_int = test_pred_int.astype(np.int)\n",
    "\n",
    "test['label'] = test_pred_int\n",
    "\n",
    "submission = test[['id','label']]\n",
    "\n",
    "submission.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset after prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train_original['label'])\n",
    "sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}